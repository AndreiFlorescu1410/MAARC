{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import MySQLdb\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librarii model\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as utils\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import warnings\n",
    "import pdb;\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(Attention, self).__init__()\n",
    "        self.op = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=in_features, out_channels=64, kernel_size=3, padding=1),\n",
    "                    nn.Conv2d(in_channels=64, out_channels=16, kernel_size=3, padding=1),\n",
    "                    nn.Conv2d(in_channels=16, out_channels=1, kernel_size=1, padding=0))\n",
    "    def forward(self, l):\n",
    "        N, C, W, H = l.size()\n",
    "        c = self.op(l)\n",
    "        a = torch.sigmoid(c)\n",
    "        g = torch.mul(a.expand_as(l), l)\n",
    "        return a.view(N,1,W,H), g\n",
    "\n",
    "class ModifyVGG(nn.Module):\n",
    "    def __init__(self, im_size, num_classes):\n",
    "        super(ModifyVGG,self).__init__()\n",
    "        vgg_model = models.vgg16(pretrained=True)\t\t\n",
    "        \n",
    "        # everything before layer 4\n",
    "        self.before_att = nn.Sequential(*list(vgg_model.features.children())[:4])\n",
    "        # added layer\n",
    "        self.attention1 = Attention(in_features=64)\n",
    "        self.attention2 = Attention(in_features=128)\n",
    "        self.attention3 = Attention(in_features=256)\n",
    "        # everything after layer 4\n",
    "        self.after_att = nn.Sequential(*list(vgg_model.features.children())[4:]) \n",
    "        self.avg_pool = vgg_model.avgpool\n",
    "        self.classifier = nn.Sequential(*list(vgg_model.classifier.children()))\n",
    "    def forward(self,x):\n",
    "      # run vgg before layer 4\n",
    "      x = self.before_att(x)\n",
    "      # run added layer\n",
    "      c1, x = self.attention1(x)\n",
    "      # run everything after layer 4 (as in the original vgg model)\n",
    "      x = self.after_att[:5](x)\n",
    "      c2, x = self.attention2(x)\n",
    "      x = self.after_att[5:12](x)\n",
    "      c3, x = self.attention3(x)\n",
    "      x = self.after_att[12:](x)\n",
    "      x = self.avg_pool(x)\n",
    "      x = x.view((x.shape[0],x.shape[1]*x.shape[2]*x.shape[3]))\n",
    "      x = self.classifier(x)\n",
    "      return x, c1, c2, c3\n",
    "IMAGE_LOCATION = 'testing/'\n",
    "def get_html_source(URL):\n",
    "    \"\"\"Docstring here.\"\"\"\n",
    "    html_source = requests.get(URL).text\n",
    "    return BeautifulSoup(html_source, 'html.parser')\n",
    "\n",
    "\n",
    "def image_name(last_name):\n",
    "    \"\"\"Docstring here.\"\"\"\n",
    "    return '{}.jpg'.format(os.path.join(IMAGE_LOCATION, str(last_name+1)))\n",
    "\n",
    "\n",
    "def validate(image_url):\n",
    "    \"\"\"Docstring here.\"\"\"\n",
    "    return image_url.endswith('.jpg') and image_url.startswith('http')\n",
    "\n",
    "\n",
    "def download_images(soup, current_name):\n",
    "    \"\"\"Docstring here.\"\"\"\n",
    "    da = soup.findAll('table','fixed offers breakword redesigned')\n",
    "    prices, links = [], []\n",
    "    for p in da[0].findAll('table'):\n",
    "        for tabel in p.findAll('td','photo-cell'):\n",
    "            for t in tabel.findChildren(\"img\"):\n",
    "                image_url = t.get('src')\n",
    "                image = requests.get(image_url)\n",
    "                if image.status_code == 200:\n",
    "                    with open(image_name(current_name), 'wb') as f:\n",
    "                        f.write(image.content)\n",
    "        for price in p.findAll('p','price'):\n",
    "            prices.append(price.get_text().strip()[:5].replace(\" \",\"\"))\n",
    "        for link in p.findAll('a','linkWithHash'):\n",
    "            links.append(link['href'])\n",
    "            break\n",
    "        current_name += 1\n",
    "\n",
    "    return current_name, prices, links\n",
    "\n",
    "def get_prices_olx(soup):\n",
    "    da = soup.findAll('table','fixed offers breakword redesigned')\n",
    "    prices, links = [], []\n",
    "    for p in da[0].findAll('table'):\n",
    "        for price in p.findAll('p','price'):\n",
    "            prices.append(price.get_text().strip()[:5].replace(\" \",\"\"))\n",
    "            break\n",
    "        for link in p.findAll('a','linkWithHash'):\n",
    "            links.append(link['href'])\n",
    "            break\n",
    "        \n",
    "    return prices, links\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = loader(image).float()\n",
    "    image = torch.tensor(image, requires_grad=True)\n",
    "    image = image.clone().detach().unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMAG\n",
    "\n",
    "def search_EMAG(URL):\n",
    "    url = 'https://www.emag.ro/search/'\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    soup\n",
    "\n",
    "\n",
    "    nr_pagini = soup.findAll(\"p\", \"product-new-price\")\n",
    "\n",
    "    preturi = []\n",
    "    for pret in nr_pagini:\n",
    "        if len(pret.text) > 0:\n",
    "            try:\n",
    "                preturi.append(int(str(pret).split(\">\",1)[1].split(\"<\",1)[0].replace('.','')))\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    link = soup.findAll(\"a\", \"thumbnail-wrapper js-product-url\", href=True)\n",
    "    links = []\n",
    "    for l in link:\n",
    "        links.append(l['href'])\n",
    "    \n",
    "    stocks = soup.findAll(\"p\",\"product-stock-status\")\n",
    "    stoc = []\n",
    "    for stock in stocks:\n",
    "        if(str(stock).split(\">\",1)[1].split(\"<\",1)[0] == \"Ã®n stoc\" or str(stock).split(\">\",1)[1].split(\"<\",1)[0] == \"\"):\n",
    "            stoc.append(2)\n",
    "        elif(str(stock).split(\">\",1)[1].split(\"<\",1)[0] == \"stoc epuizat\"):\n",
    "            stoc.append(0)\n",
    "        else:\n",
    "            stoc.append(1)\n",
    "    descs = []\n",
    "    desc = soup.findAll(\"a\", \"product-title js-product-url\")\n",
    "    for description in desc:\n",
    "        descs.append(description.get_text().strip())\n",
    "    return preturi[:5], links[:5], stoc[:5], descs[:5]\n",
    "\n",
    "def search_STRADAIT(URL):\n",
    "    url = 'https://www.stradait.ro/Produse/Filtru/Cautare:'\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    prices = soup.findAll(\"div\",\"product-price\")\n",
    "\n",
    "    preturi = []\n",
    "    for pret in prices:\n",
    "        if len(pret.text) > 0:\n",
    "            try:\n",
    "                preturi.append(int(str(pret).split(\">\",1)[1].split(\"<\",1)[0][:-4].replace('.','')[:-3]))\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "    links = []\n",
    "    for tag in soup.findAll(\"div\",\"image-product-grid img-responsive\"):\n",
    "        links.append(\"https://www.stradait.ro\" + tag.find(\"a\", href=True)['href'])\n",
    "    \n",
    "    stocks = soup.findAll(\"div\",\"stockinfo\")\n",
    "    stoc = []\n",
    "    for stock in stocks:\n",
    "        if(\"in stoc\" in str(stock).split(\">\",1)[1].split(\"<\",1)[0].lower()):\n",
    "            stoc.append(2)\n",
    "        elif(str(stock).split(\">\",1)[1].split(\"<\",1)[0] == \"Stoc epuizat\"):\n",
    "            stoc.append(0)\n",
    "        else:\n",
    "            stoc.append(1)\n",
    "    \n",
    "    descs = []\n",
    "    desc = soup.findAll(\"span\",style=re.compile(r'color:black'))\n",
    "    for description in desc:\n",
    "        descs.append(description.get_text().strip())\n",
    "    return preturi[:3], links[:3], stoc[:3], descs[:3]\n",
    "\n",
    "\n",
    "def search_CEL(URL):\n",
    "    url = 'https://www.cel.ro/cauta/'\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    prices = soup.findAll(\"b\",attrs={\"productprice\":True})\n",
    "\n",
    "    preturi = []\n",
    "    for pret in prices:\n",
    "        if len(pret.text) > 0:\n",
    "            try:\n",
    "                preturi.append(int(str(pret).split(\">\",1)[1].split(\"<\",1)[0].replace('.','')))\n",
    "            except:\n",
    "                continue\n",
    "    links = []\n",
    "    for tag in soup.findAll(\"div\",\"productListing-poza\"):\n",
    "        if(tag.find(\"a\", href=True)['href'].find(\"cel.ro\") >= 0):\n",
    "            links.append(tag.find(\"a\", href=True)['href'])\n",
    "        else:\n",
    "            links.append(\"https://www.cel.ro\" + tag.find(\"a\", href=True)['href'])\n",
    "            \n",
    "\n",
    "    text = str(soup)[str(soup).find(\"try {$('div[\"):].split(\"\\n\")\n",
    "    contor = 0\n",
    "    stoc = []\n",
    "    for line in text:\n",
    "        if(contor == 3):\n",
    "            break\n",
    "        try:\n",
    "            in_stoc = re.search(r\".*class='info_stoc .*>(.*)<.*\",line).group(1)\n",
    "            if(in_stoc == \"In stoc\"):\n",
    "                stoc.append(2)\n",
    "            else:\n",
    "                stoc.append(1)\n",
    "            contor += 1\n",
    "        except :\n",
    "            pass\n",
    "    descs = []\n",
    "    desc = soup.findAll(\"a\",\"productListing-data-b product_link product_name\")\n",
    "    for description in desc:\n",
    "        descs.append(description.get_text().strip())\n",
    "    return preturi[:3], links[:3], stoc[:3], descs[:3]\n",
    "\n",
    "\n",
    "\n",
    "def search_MEDIAGALAXY(URL):\n",
    "    url = 'https://cerberus.mediagalaxy.ro/catalog/search/'\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL,timeout=100)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    result = json.loads(str(soup))\n",
    "    \n",
    "    preturi = []\n",
    "    links = []\n",
    "    stoc = []\n",
    "    descriptions = []\n",
    "    for i in range(3):\n",
    "        preturi.append(result['products'][i]['price'])\n",
    "        links.append(\"https://mediagalaxy.ro/\" + str(result['products'][i]['url_key']) + \"/cpd/\" + str(result['products'][i]['sku']))\n",
    "        if(result['products'][i]['stock_status'] == 2):\n",
    "            stoc.append(1)\n",
    "        elif(result['products'][i]['stock_status'] == 1):\n",
    "            stoc.append(2)\n",
    "        elif(result['products'][i]['stock_status'] == 0):\n",
    "            stoc.append(0)\n",
    "        descriptions.append(result['products'][i]['name'])\n",
    "\n",
    "    return preturi, links, stoc,descriptions\n",
    "\n",
    "def search_ALTEX(URL):\n",
    "    url = 'https://fenrir.altex.ro/catalog/search/'\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL,timeout=100)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    result = json.loads(str(soup))\n",
    "    \n",
    "    preturi, links, stoc, descriptions = [] , [], [], []\n",
    "    for i in range(3):\n",
    "        preturi.append(result['products'][i]['price'])\n",
    "        links.append(\"https://altex.ro/\" + str(result['products'][i]['url_key']))\n",
    "        if(result['products'][i]['stock_status'] == 2):\n",
    "            stoc.append(1)\n",
    "        elif(result['products'][i]['stock_status'] == 1):\n",
    "            stoc.append(2)\n",
    "        elif(result['products'][i]['stock_status'] == 0):\n",
    "            stoc.append(0)\n",
    "        descriptions.append(result['products'][i]['name'])\n",
    "    return preturi, links, stoc, descriptions\n",
    "\n",
    "def search_VEXIO(URL):\n",
    "    url = 'https://sb.searchnode.net/v1/query/docs?query_key=a3nmqeRLHM2AU656Z8CnKv0xCGnitxan&search_query='\n",
    "    URL = url + URL\n",
    "    page = requests.get(URL,timeout=100)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    result = json.loads(str(soup))\n",
    "    \n",
    "    preturi = []\n",
    "    links = []\n",
    "    stoc = []\n",
    "    descriptions = []\n",
    "    for i in range(3) if len(result['docs']) >= 3 else range(len(result['docs'])):\n",
    "        preturi.append(result['docs'][i]['f_price'])\n",
    "        links.append(\"https://www.vexio.ro\" + str(result['docs'][i]['url']))\n",
    "        if(result['docs'][i]['s_stock_text'] == \"contactati-ne pentru info stoc\"):\n",
    "            stoc.append(1)\n",
    "        elif(result['docs'][i]['s_stock_text'] == \"in stoc depozit\"):\n",
    "            stoc.append(2)\n",
    "        else:\n",
    "            stoc.append(0)\n",
    "        descriptions.append(result['docs'][i]['s_title'])\n",
    "            \n",
    "    return preturi, links, stoc, descriptions\n",
    "\n",
    "\n",
    "def search_OLX(url):\n",
    "   \n",
    "    prices = []\n",
    "    links = []\n",
    "    for i in range(1,5):\n",
    "        URL = 'https://www.olx.ro/oferte/q-' + url +'/?page=' + str(i) +'&search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON'\n",
    "        soup = get_html_source(URL)\n",
    "        if((soup.findAll('input','br3')[0].get('value')) != url):\n",
    "            break\n",
    "        desc = soup.body.findAll(text=\"Asigura-te ca ai scris corect (se intampla oricui) sau incearca o cautare mai generala\")\n",
    "        if(len(desc) > 0):\n",
    "            break\n",
    "        price, link = get_prices_olx(soup)\n",
    "        for pret in price:\n",
    "            prices.append(pret)\n",
    "        for lnk in link:\n",
    "            links.append(lnk)\n",
    "    return prices, links\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def search_OLX_iphone11_11pro(url, which_phone):\n",
    "    \"\"\" phone == iphone 11 ? which_phone = 1 : which_phone = 0\"\"\"\n",
    "    model_nou = ModifyVGG(224,2)\n",
    "    model_nou.classifier[6] = nn.Linear(in_features=4096, out_features=2, bias=True)\n",
    "    model = nn.DataParallel(model_nou)\n",
    "    model.load_state_dict(torch.load(\"trained_model\"))\n",
    "    \n",
    "    prices = []\n",
    "    links = []\n",
    "    current_name = 0\n",
    "    j=0\n",
    "    for i in range(1,5):\n",
    "        URL = 'https://www.olx.ro/oferte/q-' + url + '/?page=' + str(i) +'&search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON'\n",
    "        soup = get_html_source(URL)\n",
    "        current_name, price, link = download_images(soup,current_name)\n",
    "        for pret in price:\n",
    "            prices.append(pret)\n",
    "        for lnk in link:\n",
    "            links.append(lnk)\n",
    "    i=0\n",
    "    prices_final, links_final = [], []\n",
    "    for file in os.listdir(IMAGE_LOCATION):\n",
    "        if file.endswith('.jpg'):\n",
    "            try:\n",
    "                output = (model(image_loader(data_transforms, IMAGE_LOCATION + file))[0])\n",
    "                if(F.softmax(output[0],dim=0)[which_phone] > 0.8):\n",
    "                    prices_final.append(prices[int(os.path.splitext(file)[0])-1])\n",
    "                    links_final.append(links[int(os.path.splitext(file)[0])-1])\n",
    "            except:\n",
    "                print(\"sss\") \n",
    "        i += 1\n",
    "    for file in os.listdir('testing'):\n",
    "        if file.endswith('.jpg'):\n",
    "            os.remove(\"testing/\" + file)\n",
    "    return prices_final, links_final, prices, links\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prices(siteid, prodtitle, function, lastprice):\n",
    "    \n",
    "    \n",
    "    pret, link, stoc, description = function(prodtitle)\n",
    "    prices = []\n",
    "\n",
    "\n",
    "    descriptions = []\n",
    "    for desc in description:   \n",
    "        if (siteid == 2 or siteid == 6):\n",
    "            if(desc.lower().find((prodtitle + \",\").lower()) != -1):\n",
    "                descriptions.append(desc)            \n",
    "        else:\n",
    "            if(desc.lower().find((prodtitle + \" \").lower()) != -1 or desc.lower().find((prodtitle + \",\").lower()) != -1):\n",
    "                descriptions.append(desc)\n",
    "    for desc in descriptions:\n",
    "        p = pret[description.index(desc)]\n",
    "        if(p / lastprice > 0.75):\n",
    "            prices.append(p)\n",
    "    if len(prices):\n",
    "        price_update = (min(prices))\n",
    "        link_update = (link[pret.index(min(prices))])\n",
    "        stock_update = (stoc[pret.index(min(prices))])\n",
    "        desc_update = (description[pret.index(min(prices))])\n",
    "    else:\n",
    "        price_update = (0)\n",
    "        link_update = (0)\n",
    "        stock_update = (0)\n",
    "        desc_update = prodtitle\n",
    "    return siteid, price_update, link_update, stock_update, desc_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prices(prodtitle, lastprice):\n",
    "    \"\"\" Updateaza preturile de pe toate site-urile produsulului cu id-ul idprod\"\"\"\n",
    "    update = []\n",
    "    \n",
    "    update.append([make_prices(2,prodtitle, search_ALTEX, lastprice)])\n",
    "    update.append([make_prices(6,prodtitle, search_MEDIAGALAXY, lastprice)])\n",
    "    update.append([make_prices(3,prodtitle, search_VEXIO, lastprice)])\n",
    "    update.append([make_prices(5,prodtitle, search_STRADAIT, lastprice)])\n",
    "    update.append([make_prices(4,prodtitle, search_CEL, lastprice)])\n",
    "    update.append([make_prices(1,prodtitle, search_EMAG, lastprice)])\n",
    "    return update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prices_db(idprod, prodtitle, lastprice):\n",
    "    \"\"\" Updateaza preturile din baza de date ale produslui idprod\"\"\"\n",
    "    updates = update_prices(prodtitle, lastprice)\n",
    "    if (idprod == 1):\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX_iphone11_11pro('iphone 11 pro',0)[0]]), 'https://www.olx.ro/oferte/q-iphone-11-pro/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "    elif (idprod == 18):\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX_iphone11_11pro('iphone 11',1)[0]]), 'https://www.olx.ro/oferte/q-iphone-11/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "    else:\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX(prodtitle)[0]]), 'https://www.olx.ro/oferte/q-' + prodtitle +'/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "\n",
    "    \n",
    "\n",
    "    min_price = 99999\n",
    "    for update in updates:\n",
    "        if(update[0] != 7):\n",
    "            if(min_price > round(update[0][1], 2) and round(update[0][1], 2) != 0):\n",
    "                min_price = round(update[0][1], 2)\n",
    "            sql = \"UPDATE `new_schema`.`products_price` SET `availability` = '\"+ str(update[0][3]) +\"', `price` = '\" + str((round(update[0][1], 2))) +\"', `prodtitle` = '\" + str(update[0][4]) +\"', `link` = '\" + str(update[0][2]) +\"' WHERE (`idprod` = '\" + str(idprod) +\"' and `site` = '\" + str(update[0][0]) +\"');\"\n",
    "        else:\n",
    "            olx_price = round(update[1], 2)\n",
    "            sql = \"UPDATE `new_schema`.`products_price` SET `availability` = '\"+ str(update[3]) +\"', `price` = '\" + str((round(update[1], 2))) +\"', `link` = '\" + str(update[2]) +\"' WHERE (`idprod` = '\" + str(idprod) +\"' and `site` = '\" + str(update[0]) +\"');\"\n",
    "        update_sql(sql)\n",
    "    if(not (min_price > 1000 or min_price < 10000)):\n",
    "        min_price = olx_price\n",
    "    update_sql(\"UPDATE `new_schema`.`products` SET `price` = '\" + str(min_price) + \"' WHERE (`idproducts` = '\" + str(idprod) +\"');\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_prices_db_first_time(idprod, prodtitle):\n",
    "    \"\"\" Updateaza preturile din baza de date ale produslui idprod\"\"\"\n",
    "    updates = update_prices(prodtitle, 1500)\n",
    "    if (idprod == 1):\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX_iphone11_11pro('iphone 11 pro',0)[0]]), 'https://www.olx.ro/oferte/q-iphone-11-pro/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "    elif (idprod == 18):\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX_iphone11_11pro('iphone 11',1)[0]]), 'https://www.olx.ro/oferte/q-iphone-11/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "    else:\n",
    "        updates.append([7,np.mean([int(x) for x in search_OLX(prodtitle)[0]]), 'https://www.olx.ro/oferte/q-' + prodtitle +'/?search%5Bfilter_float_price%3Afrom%5D=1500&currency=RON%27',2])\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    for update in updates:\n",
    "        if(update[0] != 7):\n",
    "            sql = \"INSERT INTO `new_schema`.`products_price` (`idprod`, `site`, `prodtitle`, `availability`, `price`, `link`) VALUES ('\"+ str(idprod) +\"', '\"+ str(update[0][0]) +\"', '\"+ str(update[0][4]) +\"', '\"+ str(update[0][3]) +\"', '\" + str(round(update[0][1], 2)) +\"', '\" + str(update[0][2]) +\"');\"\n",
    "        else:\n",
    "            sql = \"INSERT INTO `new_schema`.`products_price` (`idprod`, `site`, `prodtitle`, `availability`, `price`, `link`) VALUES ('\"+ str(idprod) +\"', '\"+ str(update[0]) +\"', '\"+ str(prodtitle) +\"', '\"+ str(update[3]) +\"', '\" + str(round(update[1], 2)) +\"', '\" + str(update[2]) +\"');\"\n",
    "        update_sql(sql)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sql(sql):\n",
    "    db = MySQLdb.connect(\"DB_IP\",\"DB_username\",\"DB_pass\",\"DB_schema\" )\n",
    "    cursor = db.cursor()\n",
    "\n",
    "\n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        db.commit()\n",
    "    except ValueError:\n",
    "        print(\"Nu am putut updata!\")\n",
    "        print(ValueError)\n",
    "        db.rollback()\n",
    "    db.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_sql(sql):\n",
    "    db = MySQLdb.connect(\"DB_ip\",\"DB_username\",\"DB_passDB_pass\",\"DB_schema\" )\n",
    "    cursor = db.cursor()\n",
    "    cursor.execute(sql)\n",
    "    results = cursor.fetchall()\n",
    "    db.close()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_to_update_first_time():\n",
    "    products_to_update = select_sql(\"SELECT * FROM new_schema.new_products;\")\n",
    "    last_id = int(select_sql(\"SELECT idproducts FROM new_schema.products ORDER BY idproducts DESC LIMIT 1;\")[0][0])\n",
    "    for product in products_to_update:\n",
    "        try:\n",
    "            last_id += 1\n",
    "            update_prices_db_first_time(last_id, product[1])\n",
    "            min_price = select_sql(\"SELECT MIN(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(last_id) + \"';\")[0][0]\n",
    "            print(\"'\"+ str(last_id) +\"', '\"+ str(min_price)+\"', '\"+ str(product[1])+\"', '\"+ str(product[2])+\"'\")\n",
    "            update_sql(\"INSERT INTO `new_schema`.`products` (`idproducts`, `prodtitle`, `price`, `prodimg`, `maker`) VALUES ('\"+ str(last_id) +\"', '\"+str(product[1]) +\"', '\"+ str(min_price)+\"', '\"+ str(product[2])+\"', '\"+ str(product[3])+\"');\")\n",
    "            min_price = select_sql(\"SELECT MIN(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(last_id) + \"' and site != 7;\")[0][0]\n",
    "            avg_price = select_sql(\"SELECT AVG(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(last_id) + \"' and site != 7;\")[0][0]\n",
    "            if(min_price == 'None'):\n",
    "                min_price = last_price\n",
    "            if(avg_price == 'None'):\n",
    "                avg_price = last_price\n",
    "            update_sql(\"INSERT INTO `new_schema`.`products_price_history` (`idprod`, `date`, `min_price`, `avg_price`) VALUES ('\"+ str(last_id) +\"', \"+ \"curdate()\" +\", '\"+ str(min_price) +\"', '\"+ str(avg_price) +\"');\")\n",
    "        except:\n",
    "            print(\"I'm going forward!\")\n",
    "    update_sql(\"DELETE FROM new_schema.new_products\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_products_to_update():\n",
    "    products_to_update = select_sql(\"SELECT * FROM new_schema.products;\")\n",
    "    for product in products_to_update:\n",
    "        print(product)\n",
    "        try:\n",
    "            if( product[2] == None):\n",
    "                last_price = 1\n",
    "            else:\n",
    "                last_price = float(product[2])\n",
    "            update_prices_db(product[0], product[1],last_price)\n",
    "            min_price = select_sql(\"SELECT MIN(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(product[0]) + \"' and site != 7;\")[0][0]\n",
    "            avg_price = select_sql(\"SELECT AVG(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(product[0]) + \"' and site != 7;\")[0][0]\n",
    "            print(\"'\"+ str(product[0]) +\"', '\"+ str(min_price)+\"', '\"+ str(product[1])+\"', '\"+ str(last_price)+\"'\")\n",
    "            if(min_price == None):\n",
    "                min_price = select_sql(\"SELECT MIN(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(product[0]) + \"' and site = 7;\")[0][0]\n",
    "            if(avg_price == None):\n",
    "                avg_price = select_sql(\"SELECT MIN(NULLIF(price, 0)) FROM new_schema.products_price WHERE idprod = '\" + str(product[0]) + \"' and site = 7;\")[0][0]\n",
    "            update_sql(\"INSERT INTO `new_schema`.`products_price_history` (`idprod`, `date`, `min_price`, `avg_price`) VALUES ('\"+ str(product[0]) +\"', \"+ \"curdate()\" +\", '\"+ str(min_price) +\"', '\"+ str(avg_price) +\"');\")\n",
    "        except:\n",
    "            print(\"I'm going forward!\")\n",
    "        print(\"--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'19', '2091.83', 'iPhone XR', 'https://s12emagst.akamaized.net/products/17043/17042909/images/res_beeb2a5b938cd2fc51ad063da79f4321_450x450_ckv0.jpg'\n"
     ]
    }
   ],
   "source": [
    "get_products_to_update_first_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'Apple iPhone 11 Pro Max', '5899', 'poze/iphone11promax.jpg', 'Apple')\n",
      "'1', '5499', 'Apple iPhone 11 Pro Max', '5899.0'\n",
      "--------------------------------\n",
      "\n",
      "(2, 'Apple iPhone X', '4549.99', 'https://s12emagst.akamaized.net/products/8892/8891494/images/res_9902358bb73d36d099ea7afc6f48cd8b_full.jpg', 'Apple')\n",
      "'2', '3769', 'Apple iPhone X', '4549.99'\n",
      "--------------------------------\n",
      "\n",
      "(9, 'Samsung Galaxy S20 Ultra', '5649', 'https://s12emagst.akamaized.net/products/30428/30427200/images/res_a2ebc264eb9d6279adaa3ca6e83a0e72_450x450_anfp.jpg', 'Samsung')\n",
      "'9', '4499.9', 'Samsung Galaxy S20 Ultra', '5649.0'\n",
      "--------------------------------\n",
      "\n",
      "(10, 'Google Pixel 4 XL', '3420.99', 'https://s12emagst.akamaized.net/products/26604/26603266/images/res_98a7671962dc515a39732150a215bc15_450x450_b3pc.jpg', 'Google')\n",
      "'10', '3414.99', 'Google Pixel 4 XL', '3420.99'\n",
      "--------------------------------\n",
      "\n",
      "(11, 'Huawei P30 Pro', '2699.9', 'https://s12emagst.akamaized.net/products/20936/20935294/images/res_ba09711c76ff81bcf7690797cb89a9c6_450x450_2add.jpg', 'Huawei')\n",
      "'11', '2449', 'Huawei P30 Pro', '2699.9'\n",
      "--------------------------------\n",
      "\n",
      "(12, 'Apple iPhone XS', '3649.9', 'https://s12emagst.akamaized.net/products/17043/17042928/images/res_9252dac902adcfcb1f3af786dc312395_450x450_8m8g.jpg', 'Apple')\n",
      "'12', '3399', 'Apple iPhone XS', '3649.9'\n",
      "--------------------------------\n",
      "\n",
      "(13, 'Apple iPhone XS Max', '6211.8', 'https://s12emagst.akamaized.net/products/17060/17059866/images/res_1ae7f1bdee21eefa970fc75e46f99c60_450x450_eptc.jpg', 'Apple')\n",
      "'13', '5249', 'Apple iPhone XS Max', '6211.8'\n",
      "--------------------------------\n",
      "\n",
      "(15, 'Samsung Galaxy S10+', '2251.75', 'https://s12emagst.akamaized.net/products/20114/20113796/images/res_ceec96ccac0833f28a969e0465a740e8_450x450_hrs.jpg', 'Samsung')\n",
      "'15', 'None', 'Samsung Galaxy S10+', '2251.75'\n",
      "--------------------------------\n",
      "\n",
      "(16, 'Samsung Galaxy S20 Plus', '3849', 'https://s12emagst.akamaized.net/products/28451/28450679/images/res_94ac97c90c5bec4a60f9d61db7b05de3_450x450_uqhd.jpg', 'Samsung')\n",
      "'16', '3849', 'Samsung Galaxy S20 Plus', '3849.0'\n",
      "--------------------------------\n",
      "\n",
      "(17, 'Huawei P20 Pro', '2110', 'https://s12emagst.akamaized.net/products/14322/14321796/images/res_3b2d0a92653e314fa6cea398a65362c2_450x450_845j.jpg', 'Huawei')\n",
      "'17', '2110', 'Huawei P20 Pro', '2110.0'\n",
      "--------------------------------\n",
      "\n",
      "(18, 'Apple iPhone 11', '3749', 'https://s12emagst.akamaized.net/products/25344/25343941/images/res_99d57ec9e3d9bb8d3242f384288ce0a3_300x300_h8j2.jpg', 'Apple')\n",
      "'18', '3749', 'Apple iPhone 11', '3749.0'\n",
      "--------------------------------\n",
      "\n",
      "(19, 'iphone xr', '4216.17', 'https://s12emagst.akamaized.net/products/17043/17042909/images/res_beeb2a5b938cd2fc51ad063da79f4321_450x450_ckv0.jpg', 'apple')\n",
      "'19', '3499', 'iphone xr', '4216.17'\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_products_to_update()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
